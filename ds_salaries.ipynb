{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. Save data to variable using Pandas. Save data to variable using python. Count how many rows and columns there are. Use pandas .describe() to see quick calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 607\n",
      "Columns: 12\n",
      "608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>6.070000e+02</td>\n",
       "      <td>607</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607</td>\n",
       "      <td>607.00000</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280</td>\n",
       "      <td>588</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>2021.405272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.240001e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112297.869852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.92257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>175.370085</td>\n",
       "      <td>0.692133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.544357e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70957.259411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.70913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2859.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>151.500000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62726.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101570.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>454.500000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.650000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>606.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.040000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    work_year experience_level employment_type  \\\n",
       "count   607.000000   607.000000              607             607   \n",
       "unique         NaN          NaN                4               4   \n",
       "top            NaN          NaN               SE              FT   \n",
       "freq           NaN          NaN              280             588   \n",
       "mean    303.000000  2021.405272              NaN             NaN   \n",
       "std     175.370085     0.692133              NaN             NaN   \n",
       "min       0.000000  2020.000000              NaN             NaN   \n",
       "25%     151.500000  2021.000000              NaN             NaN   \n",
       "50%     303.000000  2022.000000              NaN             NaN   \n",
       "75%     454.500000  2022.000000              NaN             NaN   \n",
       "max     606.000000  2022.000000              NaN             NaN   \n",
       "\n",
       "             job_title        salary salary_currency  salary_in_usd  \\\n",
       "count              607  6.070000e+02             607     607.000000   \n",
       "unique              50           NaN              17            NaN   \n",
       "top     Data Scientist           NaN             USD            NaN   \n",
       "freq               143           NaN             398            NaN   \n",
       "mean               NaN  3.240001e+05             NaN  112297.869852   \n",
       "std                NaN  1.544357e+06             NaN   70957.259411   \n",
       "min                NaN  4.000000e+03             NaN    2859.000000   \n",
       "25%                NaN  7.000000e+04             NaN   62726.000000   \n",
       "50%                NaN  1.150000e+05             NaN  101570.000000   \n",
       "75%                NaN  1.650000e+05             NaN  150000.000000   \n",
       "max                NaN  3.040000e+07             NaN  600000.000000   \n",
       "\n",
       "       employee_residence  remote_ratio company_location company_size  \n",
       "count                 607     607.00000              607          607  \n",
       "unique                 57           NaN               50            3  \n",
       "top                    US           NaN               US            M  \n",
       "freq                  332           NaN              355          326  \n",
       "mean                  NaN      70.92257              NaN          NaN  \n",
       "std                   NaN      40.70913              NaN          NaN  \n",
       "min                   NaN       0.00000              NaN          NaN  \n",
       "25%                   NaN      50.00000              NaN          NaN  \n",
       "50%                   NaN     100.00000              NaN          NaN  \n",
       "75%                   NaN     100.00000              NaN          NaN  \n",
       "max                   NaN     100.00000              NaN          NaN  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import statistics\n",
    "df = pd.read_csv('data_files/ds_salaries.csv')\n",
    "total_rows = len(df.axes[0])\n",
    "total_columns = len(df.axes[1])\n",
    "print(f\"Rows: {total_rows}\")\n",
    "print(f\"Columns: {total_columns}\")\n",
    "ds_data = 'data_files/ds_salaries.csv'\n",
    "\n",
    "with open(ds_data) as data:\n",
    "    count = 0\n",
    "    for line in data.readlines():\n",
    "        count += 1\n",
    "    print(count)\n",
    "df.describe(include = 'all')\n",
    "# df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I am going to separate out the information in the columns into lists.\n",
    "I will do that for each column so I can clean the columns. I will do this without Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work_year', 'experience_level', 'employment_type', 'job_title', 'salary', 'salary_currency', 'salary_in_usd', 'employee_residence', 'remote_ratio', 'company_location', 'company_size']\n"
     ]
    }
   ],
   "source": [
    "def get_column_names(data):\n",
    "    with open(data) as data:\n",
    "        columns = data.readline()\n",
    "        each = columns.strip(',').strip().split(',')\n",
    "    return each\n",
    "list_column_names = get_column_names(ds_data)\n",
    "print(list_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty lists to append each column's content to, so I can look at them each individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_year = []\n",
    "experience_level = []\n",
    "employment_type = []\n",
    "job_title = []\n",
    "salary = []\n",
    "salary_currency = []\n",
    "salary_in_usd = []\n",
    "employee_residence = []\n",
    "remote_ratio = []\n",
    "company_location = []\n",
    "company_size = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data = 'data_files/ds_salaries.csv'\n",
    "def data_as_dict(data):\n",
    "    with open(data, newline='') as ds_data:\n",
    "        dict_data = []\n",
    "        data = csv.DictReader(ds_data)\n",
    "        for row in data:\n",
    "            row.pop('')\n",
    "            dict_data.append(row)\n",
    "        return dict_data\n",
    "list_data = data_as_dict(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list_data to append data in each column to corresponding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = data_as_dict(ds_data)\n",
    "def add_to_list(lists, to_add):\n",
    "    for i in list_data:\n",
    "        lists.append(i[to_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_list(work_year, 'work_year')\n",
    "add_to_list(experience_level, 'experience_level')\n",
    "add_to_list(employment_type, 'employment_type')\n",
    "add_to_list(job_title, 'job_title')\n",
    "add_to_list(salary, 'salary')\n",
    "add_to_list(salary_currency, 'salary_currency')\n",
    "add_to_list(salary_in_usd, 'salary_in_usd')\n",
    "add_to_list(employee_residence, 'employee_residence')\n",
    "add_to_list(remote_ratio, 'remote_ratio')\n",
    "add_to_list(company_location, 'company_location')\n",
    "add_to_list(company_size, 'company_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure work_year doesn't have any outliers. Also check how many data points for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_2020 = 0\n",
    "count_2021 = 0\n",
    "count_2022 = 0\n",
    "count_na = 0\n",
    "for i in range(len(work_year)):\n",
    "    if work_year[i] != '2020' and work_year[i] != '2021' and work_year[i] != '2022':\n",
    "        count_na += 1\n",
    "    elif work_year[i] == '2020':\n",
    "        count_2020 += 1\n",
    "    elif work_year[i] == '2021':\n",
    "        count_2021 += 1\n",
    "    elif work_year[i] == '2022':\n",
    "        count_2022 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 Work Year: 72\n",
      "2021 Work Year: 217\n",
      "2022 Work Year: 318\n",
      "Other Years: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"2020 Work Year: {count_2020}\")\n",
    "print(f\"2021 Work Year: {count_2021}\")\n",
    "print(f\"2022 Work Year: {count_2022}\")\n",
    "print(f\"Other Years: {count_na}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string values in salary, size, etc. lists to integers to perform calculations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = list(map(int, salary))\n",
    "salary_in_usd = list(map(int, salary_in_usd))\n",
    "remote_ratio = list(map(int, remote_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324,000.06\n"
     ]
    }
   ],
   "source": [
    "average_salary = f'{statistics.mean(salary):,.2f}'\n",
    "print(average_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112,297.87\n"
     ]
    }
   ],
   "source": [
    "avg_salary_usd = f'{statistics.mean(salary_in_usd):,.2f}'\n",
    "print(avg_salary_usd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average salary(USD) for each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2020': 95813.0, '2021': 99853.79262672811, '2022': 124522.00628930818}\n"
     ]
    }
   ],
   "source": [
    "def salary_per_year(year, salary):\n",
    "    salary_year = [{key:value} for key,value in zip(year, salary)]\n",
    "    average_salary_2020 = 0\n",
    "    average_salary_2021 = 0\n",
    "    average_salary_2022 = 0\n",
    "    for dict in salary_year:\n",
    "        for key,value in dict.items():\n",
    "            if key == '2020':\n",
    "                average_salary_2020 += value\n",
    "            elif key == '2021':\n",
    "                average_salary_2021 += value\n",
    "            else:\n",
    "                average_salary_2022 += value\n",
    "    avg_2020 = average_salary_2020/count_2020\n",
    "    avg_2021 = average_salary_2021/count_2021\n",
    "    avg_2022 = average_salary_2022/count_2022\n",
    "    return {'2020': avg_2020, '2021': avg_2021, '2022': avg_2022}\n",
    "    \n",
    "avg_salary_year = salary_per_year(work_year, salary_in_usd)\n",
    "print(avg_salary_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average salary(USD) for each year? *Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year  salary_in_usd\n",
      "0       2020   95813.000000\n",
      "1       2021   99853.792627\n",
      "2       2022  124522.006289\n"
     ]
    }
   ],
   "source": [
    "annual_salary = df.groupby('work_year').salary_in_usd.mean().reset_index()\n",
    "print(annual_salary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average annual salary(USD) for each positiion? *Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique job titles in data set: 50\n",
      "        Category              Max Avg.\n",
      "0      work_year                  2022\n",
      "1      job_title  Staff Data Scientist\n",
      "2  salary_in_usd              450000.0\n"
     ]
    }
   ],
   "source": [
    "# Determine how many different job_titles are represented in data set.\n",
    "no_job_titles = df.job_title.nunique()\n",
    "print(f\"Number of unique job titles in data set: {no_job_titles}\")\n",
    "# Create DataFrame that looks at average salary of each work year and job title.\n",
    "annual_salary_per_title = df.groupby(['work_year', 'job_title']).salary_in_usd.mean().reset_index()\n",
    "# Create a pivot table to visualize data more comprehensively\n",
    "annual_salary_per_title_pivot = annual_salary_per_title.pivot(columns='work_year', index='job_title', values='salary_in_usd')\n",
    "# print(annual_salary_per_title_pivot)\n",
    "# Find job_title and year that has the greates annual salary.\n",
    "title_max_avg_salary = annual_salary_per_title.max().reset_index().rename(columns={0:'Max Avg.', 'index': 'Category'})\n",
    "print(title_max_avg_salary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many each times job_title is represented in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Data Scientist': 143}, {'Machine Learning Scientist': 8}, {'Big Data Engineer': 8}, {'Product Data Analyst': 2}, {'Machine Learning Engineer': 41}, {'Data Analyst': 97}, {'Lead Data Scientist': 3}, {'Business Data Analyst': 5}, {'Lead Data Engineer': 6}, {'Lead Data Analyst': 3}, {'Data Engineer': 132}, {'Data Science Consultant': 7}, {'BI Data Analyst': 6}, {'Director of Data Science': 7}, {'Research Scientist': 16}, {'Machine Learning Manager': 1}, {'Data Engineering Manager': 5}, {'Machine Learning Infrastructure Engineer': 3}, {'ML Engineer': 6}, {'AI Scientist': 7}, {'Computer Vision Engineer': 6}, {'Principal Data Scientist': 7}, {'Data Science Manager': 12}, {'Head of Data': 5}, {'3D Computer Vision Researcher': 1}, {'Data Analytics Engineer': 4}, {'Applied Data Scientist': 5}, {'Marketing Data Analyst': 1}, {'Cloud Data Engineer': 2}, {'Financial Data Analyst': 2}, {'Computer Vision Software Engineer': 3}, {'Director of Data Engineering': 2}, {'Data Science Engineer': 3}, {'Principal Data Engineer': 3}, {'Machine Learning Developer': 3}, {'Applied Machine Learning Scientist': 4}, {'Data Analytics Manager': 7}, {'Head of Data Science': 4}, {'Data Specialist': 1}, {'Data Architect': 11}, {'Finance Data Analyst': 1}, {'Principal Data Analyst': 2}, {'Big Data Architect': 1}, {'Staff Data Scientist': 1}, {'Analytics Engineer': 4}, {'ETL Developer': 2}, {'Head of Machine Learning': 1}, {'NLP Engineer': 1}, {'Lead Machine Learning Engineer': 1}, {'Data Analytics Lead': 1}]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of different job_types represented in the data set.\n",
    "types_of_jobs = df.job_title.unique()\n",
    "# Create a function that outputs the times each job_title is respresented.\n",
    "def number_represented(job):\n",
    "    count = 0\n",
    "    for i in job_title:\n",
    "        if i == job:\n",
    "            count += 1\n",
    "    return count\n",
    "# Create an empty array to append key:value pairs.\n",
    "number_of_types_of_jobs = []\n",
    "# Iterate through each job in type_of_jobs and appending dict w/ job_type as key and number of times that job is represented as the value.\n",
    "for i in types_of_jobs:\n",
    "    number_of_types_of_jobs.append({i:number_represented(i)})\n",
    "print(number_of_types_of_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average and median salary for each experience level?\n",
    "EN Entry-level/Junior -- MI Mid-level/Intermediate -- SE Senior-level/Expert -- EX Executive-level/Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_EN = 0\n",
    "count_MI = 0\n",
    "count_SE = 0\n",
    "count_EX = 0\n",
    "for i in experience_level:\n",
    "    if i == 'EN':\n",
    "        count_EN += 1\n",
    "    elif i == 'MI':\n",
    "        count_MI += 1\n",
    "    elif i == 'SE':\n",
    "        count_SE += 1\n",
    "    elif i == 'EX':\n",
    "        count_EX += 1\n",
    "    else:\n",
    "        print('oops')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Entry Level Salary': 61643.318181818184, 'Mid Level Salary': 87996.05633802817, 'Senior Level Salary': 138617.29285714286, 'Director Level Salary': 199392.03846153847}\n"
     ]
    }
   ],
   "source": [
    "def experience_level_salary(level, salary):\n",
    "    total_EN = 0\n",
    "    total_MI = 0\n",
    "    total_SE = 0\n",
    "    total_EX = 0\n",
    "    dict_level_salary = [{key:value} for key,value in zip(level, salary)]\n",
    "    # print(len(dict_level_salary))\n",
    "    for dict in dict_level_salary:\n",
    "        for key, value in dict.items():\n",
    "            if key == 'EN':\n",
    "                total_EN += value\n",
    "            elif key == 'MI':\n",
    "                total_MI += value\n",
    "            elif key == 'SE':\n",
    "                total_SE += value\n",
    "            else:\n",
    "                total_EX += value\n",
    "    avg_EN = total_EN/count_EN\n",
    "    avg_MI = total_MI/count_MI\n",
    "    avg_SE = total_SE/count_SE\n",
    "    avg_EX = total_EX/count_EX\n",
    "    return {'Entry Level Salary': avg_EN, 'Mid Level Salary': avg_MI, 'Senior Level Salary': avg_SE, 'Director Level Salary': avg_EX}\n",
    "dict_of_salary_per_level = experience_level_salary(experience_level, salary_in_usd)\n",
    "print(dict_of_salary_per_level)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average salary for a level for a position? *Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_level_salary = df.groupby(['experience_level','job_title']).salary_in_usd.mean().reset_index().pivot(columns='experience_level', index='job_title', values='salary_in_usd')\n",
    "# print(position_level_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What different company_locations are there, how many and where?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coutries w/ code:\n",
    "DE = Germany                \n",
    "JP = Japan\n",
    "GB = UK\n",
    "HN = Honduras\n",
    "US = United States\n",
    "HU = Hungary\n",
    "NZ = New Zealand\n",
    "FR = France\n",
    "IN = India\n",
    "PK - Pakistan\n",
    "CN = China\n",
    "GR = Greece\n",
    "AE = UAE\n",
    "NL = Netherlands\n",
    "MX - Mexico\n",
    "CA = Canada\n",
    "AT = Austria\n",
    "NG = Nigeria\n",
    "ES = Spain\n",
    "PT = Portugal\n",
    "DK = Denmark\n",
    "IT = Italy\n",
    "HR = Croatia\n",
    "LU = Luxembourg\n",
    "PL = Poland\n",
    "SG = Singapore\n",
    "RO = Romania\n",
    "IQ = Iraq\n",
    "BR = Brazil\n",
    "BE = Belgium\n",
    "UA = Ukraine\n",
    "IL = Israel\n",
    "RU = Russia\n",
    "MT = Malta\n",
    "CL = Chile\n",
    "IR = Iran\n",
    "CO = Columbia\n",
    "MD = Moldova\n",
    "KE = Kenya\n",
    "SI = Slovenia\n",
    "CH = Switzerland\n",
    "VN = Vietnam\n",
    "AS = American Samoa\n",
    "TR = Turkey\n",
    "CZ = Chech Republic\n",
    "DZ = Algeria\n",
    "EE = Estonia\n",
    "MY = Malaysia\n",
    "AU = Australia\n",
    "IE = Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607\n",
      "50\n",
      "['DE' 'JP' 'GB' 'HN' 'US' 'HU' 'NZ' 'FR' 'IN' 'PK' 'CN' 'GR' 'AE' 'NL'\n",
      " 'MX' 'CA' 'AT' 'NG' 'ES' 'PT' 'DK' 'IT' 'HR' 'LU' 'PL' 'SG' 'RO' 'IQ'\n",
      " 'BR' 'BE' 'UA' 'IL' 'RU' 'MT' 'CL' 'IR' 'CO' 'MD' 'KE' 'SI' 'CH' 'VN'\n",
      " 'AS' 'TR' 'CZ' 'DZ' 'EE' 'MY' 'AU' 'IE']\n"
     ]
    }
   ],
   "source": [
    "def update_country_code(codes):\n",
    "    country_name = {'DE': 'Germany', 'JP': 'Japan', 'GB': 'UK', 'HN': 'Honduras', 'US': 'United States', 'HU': 'Hungary', 'NZ': 'New Zealand', 'FR': 'France', 'IN': 'India', 'PK': 'Pakistan', 'CN': 'China', 'GR': 'Greece', 'AE': 'UAE', 'NL': 'Netherlands', 'MX': 'Mexico', 'CA': 'Canada', 'AT': 'Austria', 'NG': 'Nigeria', 'ES': 'Spain', 'PT': 'Portugal', 'DK': 'Denmark', 'IT': 'Italy', 'HR': 'Croatia', 'LU': 'Luxembourg', 'PL': 'Poland', 'SG': 'Singapore', 'RO': 'Romania', 'IQ': 'Iraq', 'BR': 'Brazil', 'BE': 'Belgium', 'UA': 'Ukraine', 'IL': 'Israel', 'RU': 'Russia', 'MT': 'Malta', 'CL': 'Chile', 'IR': 'Iran', 'CO': 'Columbia', 'MD': 'Moldova', 'KE': 'Kenya', 'SI': 'Slovenia', 'CH': 'Switzerland', 'VN': 'Vietnam', 'AS': 'American Samoa', 'TR': 'Turkey', 'CZ': 'Czech Republic', 'DZ': 'Algeria', 'EE': 'Estonia', 'MY': 'Malaysia', 'AU': 'Australia', 'IE': 'Ireland', 'BG': 'Bulgaria', 'PH': 'Philippines', 'RS': 'Serbia', 'AR': 'Argentina', 'TN': 'Tunisia', 'BO': 'Bolivia', 'PR': 'Puerto Rico', 'JE': 'Jersey'}\n",
    "    for code, name  in country_name.items():\n",
    "        for i in range(len(codes)):\n",
    "            if code == codes[i]:\n",
    "                codes[i] = name\n",
    "update_country_code(company_location)\n",
    "update_country_code(employee_residence)\n",
    "# print(company_location)\n",
    "print(employee_residence)\n",
    "number_locations = df.company_location.nunique()\n",
    "print(number_locations)\n",
    "company_unique_locations = df.company_location.unique()\n",
    "print(company_unique_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States Avg Salary: 144055.26197183097\n",
      "United States Avg Salary: 149194.1174698795\n"
     ]
    }
   ],
   "source": [
    "def avg_US_salary(salary, location):\n",
    "    dict_salary_location = [{key:value} for key, value in zip(location, salary)]\n",
    "    total_US = 0\n",
    "    count_US = 0\n",
    "    for dict in dict_salary_location:\n",
    "        for key, value in dict.items():\n",
    "            if key == 'United States':\n",
    "                total_US += value\n",
    "                count_US += 1\n",
    "    avg_US = total_US/count_US\n",
    "    return f\"United States Avg Salary: {avg_US}\"\n",
    "avg_US_company_salary = avg_US_salary(salary_in_usd, company_location)\n",
    "print(avg_US_company_salary)\n",
    "avg_US_employee_salary = avg_US_salary(salary_in_usd, employee_residence)\n",
    "print(avg_US_employee_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average salary in the US by experience level? *Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_salary_company_level = df.groupby(['experience_level', 'company_location']).salary_in_usd.mean().reset_index().pivot(columns='experience_level', index='company_location', values='salary_in_usd')\n",
    "average_salary_employee_level = df.groupby(['experience_level', 'employee_residence']).salary_in_usd.mean().reset_index().pivot(columns='experience_level', index='employee_residence', values='salary_in_usd')\n",
    "# print(average_salary_company_level)\n",
    "# print(average_salary_employee_level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of all data with keys' being indices (zero indexed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_in_list = list(zip(work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size))\n",
    "# print(all_data)\n",
    "def create_dictionary(data):\n",
    "    l = len(data)\n",
    "    dict_all_data = {}\n",
    "    for i in range(l):\n",
    "        dict_all_data[i] = {'work_year': data[i][0],\n",
    "                            'experience_level': data[i][1],\n",
    "                            'employment_type': data[i][2],\n",
    "                            'job_title': data[i][3],\n",
    "                            'salary': data[i][4],\n",
    "                            'salary_currency': data[i][5],\n",
    "                            'salary_in_usd': data[i][6],\n",
    "                            'employee_residence': data[i][7],\n",
    "                            'remote_ratio': data[i][8],\n",
    "                            'company_location': data[i][9],\n",
    "                            'company_size': data[i][10]}\n",
    "    return dict_all_data\n",
    "data_dict = create_dictionary(all_data_in_list)\n",
    "\n",
    "# print(data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "check = pd.DataFrame(df)\n",
    "duplicate = check[check.duplicated()]\n",
    "print(len(duplicate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dictionary of data to specify certain variable values.\n",
    "What is the average salary of entry level data scientists in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88833.33333333333\n"
     ]
    }
   ],
   "source": [
    "def salary_DS_US_EN(dict):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for i in range(len(dict)):\n",
    "        if dict[i]['experience_level'] == 'EN' and dict[i]['company_location'] == 'United States' and dict[i]['job_title'] == 'Data Scientist':\n",
    "            total += dict[i]['salary_in_usd']\n",
    "            count += 1\n",
    "    avg = total/count\n",
    "    return avg\n",
    "avg_salary_DS_US_EN = salary_DS_US_EN(data_dict)\n",
    "print(avg_salary_DS_US_EN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3d8a8be75f9e7e90c92f56a26dc284ac664b6f4edfe25f866cebb8c85a664d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
